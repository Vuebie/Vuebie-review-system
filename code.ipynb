{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255641b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T16:25:28.489203Z",
     "iopub.status.busy": "2025-07-27T16:25:28.488954Z",
     "iopub.status.idle": "2025-07-27T16:25:28.526369Z",
     "shell.execute_reply": "2025-07-27T16:25:28.525667Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2445020747.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import { useState, useEffect } from 'react';\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import { useState, useEffect } from 'react';\n",
    "import { supabase } from '../lib/supabase';\n",
    "import permissionCache from '../lib/permission-cache';\n",
    "\n",
    "/**\n",
    " * Permission Monitoring Service\n",
    " * Captures and tracks metrics about the permission system\n",
    " */\n",
    "export class PermissionMonitoringService {\n",
    "  private static instance: PermissionMonitoringService;\n",
    "  private metrics: {\n",
    "    // Cache metrics\n",
    "    cacheHits: number;\n",
    "    cacheMisses: number;\n",
    "    cacheSize: number;\n",
    "    cacheExpirations: number;\n",
    "    cacheInvalidations: number;\n",
    "    \n",
    "    // Permission check metrics\n",
    "    permissionChecks: number;\n",
    "    permissionChecksByResource: Record<string, number>;\n",
    "    permissionChecksByAction: Record<string, number>;\n",
    "    permissionGranted: number;\n",
    "    permissionDenied: number;\n",
    "    permissionErrors: number;\n",
    "    permissionCheckLatency: number[];\n",
    "    \n",
    "    // Role management metrics\n",
    "    roleAssignments: number;\n",
    "    roleRemovals: number;\n",
    "    \n",
    "    // Security events\n",
    "    unauthorizedAccessAttempts: number;\n",
    "    \n",
    "    // Edge function metrics\n",
    "    edgeFunctionCalls: number;\n",
    "    edgeFunctionErrors: number;\n",
    "    edgeFunctionLatency: number[];\n",
    "  };\n",
    "  \n",
    "  private eventLog: {\n",
    "    timestamp: Date;\n",
    "    eventType: string;\n",
    "    details: any;\n",
    "  }[] = [];\n",
    "  \n",
    "  private constructor() {\n",
    "    // Initialize metrics\n",
    "    this.metrics = {\n",
    "      // Cache metrics\n",
    "      cacheHits: 0,\n",
    "      cacheMisses: 0,\n",
    "      cacheSize: 0,\n",
    "      cacheExpirations: 0,\n",
    "      cacheInvalidations: 0,\n",
    "      \n",
    "      // Permission check metrics\n",
    "      permissionChecks: 0,\n",
    "      permissionChecksByResource: {},\n",
    "      permissionChecksByAction: {},\n",
    "      permissionGranted: 0,\n",
    "      permissionDenied: 0,\n",
    "      permissionErrors: 0,\n",
    "      permissionCheckLatency: [],\n",
    "      \n",
    "      // Role management metrics\n",
    "      roleAssignments: 0,\n",
    "      roleRemovals: 0,\n",
    "      \n",
    "      // Security events\n",
    "      unauthorizedAccessAttempts: 0,\n",
    "      \n",
    "      // Edge function metrics\n",
    "      edgeFunctionCalls: 0,\n",
    "      edgeFunctionErrors: 0,\n",
    "      edgeFunctionLatency: [],\n",
    "    };\n",
    "    \n",
    "    this.monkeyPatchPermissionCache();\n",
    "    this.monkeyPatchPermissionFunctions();\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Get the singleton instance\n",
    "   */\n",
    "  public static getInstance(): PermissionMonitoringService {\n",
    "    if (!PermissionMonitoringService.instance) {\n",
    "      PermissionMonitoringService.instance = new PermissionMonitoringService();\n",
    "    }\n",
    "    return PermissionMonitoringService.instance;\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Extend the PermissionCache to track cache metrics\n",
    "   */\n",
    "  private monkeyPatchPermissionCache(): void {\n",
    "    const originalGet = permissionCache.get;\n",
    "    const originalSet = permissionCache.set;\n",
    "    const originalDelete = permissionCache.delete;\n",
    "    const originalInvalidateUserPermissions = permissionCache.invalidateUserPermissions;\n",
    "    const self = this;\n",
    "    \n",
    "    // Override get method to track hits and misses\n",
    "    permissionCache.get = function<T>(key: string): T | undefined {\n",
    "      const startTime = performance.now();\n",
    "      const value = originalGet.call(this, key);\n",
    "      const endTime = performance.now();\n",
    "      \n",
    "      if (value === undefined) {\n",
    "        self.metrics.cacheMisses++;\n",
    "        self.logEvent('CACHE_MISS', { key });\n",
    "      } else {\n",
    "        self.metrics.cacheHits++;\n",
    "        self.logEvent('CACHE_HIT', { key });\n",
    "      }\n",
    "      \n",
    "      self.updateCacheSize();\n",
    "      return value;\n",
    "    };\n",
    "    \n",
    "    // Override set method to track cache updates\n",
    "    permissionCache.set = function<T>(key: string, value: T, ttl?: number): void {\n",
    "      originalSet.call(this, key, value, ttl);\n",
    "      self.updateCacheSize();\n",
    "      self.logEvent('CACHE_SET', { key });\n",
    "    };\n",
    "    \n",
    "    // Override delete method to track cache deletions\n",
    "    permissionCache.delete = function(key: string): void {\n",
    "      originalDelete.call(this, key);\n",
    "      self.updateCacheSize();\n",
    "      self.logEvent('CACHE_DELETE', { key });\n",
    "    };\n",
    "    \n",
    "    // Override invalidateUserPermissions to track invalidations\n",
    "    permissionCache.invalidateUserPermissions = function(userId: string): void {\n",
    "      originalInvalidateUserPermissions.call(this, userId);\n",
    "      self.metrics.cacheInvalidations++;\n",
    "      self.updateCacheSize();\n",
    "      self.logEvent('CACHE_INVALIDATE', { userId });\n",
    "    };\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Track the current size of the cache\n",
    "   */\n",
    "  private updateCacheSize(): void {\n",
    "    // Use Object.keys on the private cache property\n",
    "    // This is a bit hacky but works for monitoring\n",
    "    // @ts-ignore - Accessing private property\n",
    "    if (permissionCache.cache && permissionCache.cache instanceof Map) {\n",
    "      // @ts-ignore - Accessing private property\n",
    "      this.metrics.cacheSize = permissionCache.cache.size;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Extend the permission functions to track metrics\n",
    "   */\n",
    "  private monkeyPatchPermissionFunctions(): void {\n",
    "    // Import the permission functions dynamically to avoid circular dependencies\n",
    "    import('../lib/permission').then((permissionModule) => {\n",
    "      const originalCheckPermission = permissionModule.checkPermission;\n",
    "      const originalAssignRoleToUser = permissionModule.assignRoleToUser;\n",
    "      const originalRemoveRoleFromUser = permissionModule.removeRoleFromUser;\n",
    "      const self = this;\n",
    "      \n",
    "      // Override checkPermission to track permission checks\n",
    "      permissionModule.checkPermission = async function(userId: string, resource: string, action: string): Promise<boolean> {\n",
    "        self.metrics.permissionChecks++;\n",
    "        \n",
    "        // Track checks by resource\n",
    "        self.metrics.permissionChecksByResource[resource] = \n",
    "          (self.metrics.permissionChecksByResource[resource] || 0) + 1;\n",
    "        \n",
    "        // Track checks by action\n",
    "        self.metrics.permissionChecksByAction[action] = \n",
    "          (self.metrics.permissionChecksByAction[action] || 0) + 1;\n",
    "        \n",
    "        const startTime = performance.now();\n",
    "        try {\n",
    "          const result = await originalCheckPermission.call(this, userId, resource, action);\n",
    "          const endTime = performance.now();\n",
    "          \n",
    "          // Record latency\n",
    "          self.metrics.permissionCheckLatency.push(endTime - startTime);\n",
    "          \n",
    "          // Track result\n",
    "          if (result) {\n",
    "            self.metrics.permissionGranted++;\n",
    "            self.logEvent('PERMISSION_GRANTED', { userId, resource, action });\n",
    "          } else {\n",
    "            self.metrics.permissionDenied++;\n",
    "            self.logEvent('PERMISSION_DENIED', { userId, resource, action });\n",
    "          }\n",
    "          \n",
    "          return result;\n",
    "        } catch (error) {\n",
    "          self.metrics.permissionErrors++;\n",
    "          self.logEvent('PERMISSION_ERROR', { userId, resource, action, error });\n",
    "          throw error;\n",
    "        }\n",
    "      };\n",
    "      \n",
    "      // Override assignRoleToUser to track role assignments\n",
    "      permissionModule.assignRoleToUser = async function(userId: string, roleName: string): Promise<boolean> {\n",
    "        try {\n",
    "          const result = await originalAssignRoleToUser.call(this, userId, roleName);\n",
    "          if (result) {\n",
    "            self.metrics.roleAssignments++;\n",
    "            self.logEvent('ROLE_ASSIGNED', { userId, roleName });\n",
    "          }\n",
    "          return result;\n",
    "        } catch (error) {\n",
    "          self.logEvent('ROLE_ASSIGNMENT_ERROR', { userId, roleName, error });\n",
    "          throw error;\n",
    "        }\n",
    "      };\n",
    "      \n",
    "      // Override removeRoleFromUser to track role removals\n",
    "      permissionModule.removeRoleFromUser = async function(userId: string, roleName: string): Promise<boolean> {\n",
    "        try {\n",
    "          const result = await originalRemoveRoleFromUser.call(this, userId, roleName);\n",
    "          if (result) {\n",
    "            self.metrics.roleRemovals++;\n",
    "            self.logEvent('ROLE_REMOVED', { userId, roleName });\n",
    "          }\n",
    "          return result;\n",
    "        } catch (error) {\n",
    "          self.logEvent('ROLE_REMOVAL_ERROR', { userId, roleName, error });\n",
    "          throw error;\n",
    "        }\n",
    "      };\n",
    "    });\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Log an event to the event log\n",
    "   */\n",
    "  private logEvent(eventType: string, details: any): void {\n",
    "    this.eventLog.push({\n",
    "      timestamp: new Date(),\n",
    "      eventType,\n",
    "      details\n",
    "    });\n",
    "    \n",
    "    // Keep event log at a reasonable size\n",
    "    if (this.eventLog.length > 1000) {\n",
    "      this.eventLog.shift();\n",
    "    }\n",
    "    \n",
    "    // For serious security events, send to audit logs in the database\n",
    "    if (\n",
    "      eventType === 'PERMISSION_DENIED' || \n",
    "      eventType === 'UNAUTHORIZED_ACCESS' ||\n",
    "      eventType.includes('ERROR')\n",
    "    ) {\n",
    "      this.logToAuditDatabase(eventType, details);\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Log critical events to the audit logs database\n",
    "   */\n",
    "  private async logToAuditDatabase(eventType: string, details: any): Promise<void> {\n",
    "    try {\n",
    "      const userId = details.userId || 'system';\n",
    "      await supabase.from('app_0be8fb8541_audit_logs').insert({\n",
    "        user_id: userId,\n",
    "        action_type: eventType,\n",
    "        resource_type: 'PERMISSION',\n",
    "        resource_id: details.resource || null,\n",
    "        details\n",
    "      });\n",
    "    } catch (error) {\n",
    "      console.error('Failed to log to audit database:', error);\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Get current metrics\n",
    "   */\n",
    "  public getMetrics() {\n",
    "    return {\n",
    "      ...this.metrics,\n",
    "      \n",
    "      // Calculate derived metrics\n",
    "      cacheHitRate: this.calculateCacheHitRate(),\n",
    "      averagePermissionCheckLatency: this.calculateAverageLatency(this.metrics.permissionCheckLatency),\n",
    "      averageEdgeFunctionLatency: this.calculateAverageLatency(this.metrics.edgeFunctionLatency),\n",
    "      eventLog: this.getRecentEvents(50)\n",
    "    };\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Calculate cache hit rate\n",
    "   */\n",
    "  private calculateCacheHitRate(): number {\n",
    "    const total = this.metrics.cacheHits + this.metrics.cacheMisses;\n",
    "    return total > 0 ? this.metrics.cacheHits / total : 0;\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Calculate average latency from an array of latency measurements\n",
    "   */\n",
    "  private calculateAverageLatency(latencyArray: number[]): number {\n",
    "    if (latencyArray.length === 0) return 0;\n",
    "    const sum = latencyArray.reduce((acc, val) => acc + val, 0);\n",
    "    return sum / latencyArray.length;\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Get recent events from the event log\n",
    "   */\n",
    "  private getRecentEvents(count: number): typeof this.eventLog {\n",
    "    return this.eventLog.slice(-count);\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Reset metrics (for testing or time-based resets)\n",
    "   */\n",
    "  public resetMetrics(): void {\n",
    "    this.metrics = {\n",
    "      cacheHits: 0,\n",
    "      cacheMisses: 0,\n",
    "      cacheSize: this.metrics.cacheSize, // Keep current cache size\n",
    "      cacheExpirations: 0,\n",
    "      cacheInvalidations: 0,\n",
    "      \n",
    "      permissionChecks: 0,\n",
    "      permissionChecksByResource: {},\n",
    "      permissionChecksByAction: {},\n",
    "      permissionGranted: 0,\n",
    "      permissionDenied: 0,\n",
    "      permissionErrors: 0,\n",
    "      permissionCheckLatency: [],\n",
    "      \n",
    "      roleAssignments: 0,\n",
    "      roleRemovals: 0,\n",
    "      \n",
    "      unauthorizedAccessAttempts: 0,\n",
    "      \n",
    "      edgeFunctionCalls: 0,\n",
    "      edgeFunctionErrors: 0,\n",
    "      edgeFunctionLatency: [],\n",
    "    };\n",
    "  }\n",
    "}\n",
    "\n",
    "// Export singleton instance\n",
    "export default PermissionMonitoringService.getInstance();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94434759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T16:26:55.082078Z",
     "iopub.status.busy": "2025-07-27T16:26:55.081723Z",
     "iopub.status.idle": "2025-07-27T16:26:56.394159Z",
     "shell.execute_reply": "2025-07-27T16:26:56.392793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 09:26:55.664 | INFO     | metagpt.const:get_metagpt_root:33 - PROJECT_ROOT set from environment variable to /\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmetagpt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mterminal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Terminal\n\u001b[1;32m      2\u001b[0m terminal \u001b[38;5;241m=\u001b[39m Terminal()\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/__init__.py:46\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     ArrowDtype,\n\u001b[1;32m     49\u001b[0m     Int8Dtype,\n\u001b[1;32m     50\u001b[0m     Int16Dtype,\n\u001b[1;32m     51\u001b[0m     Int32Dtype,\n\u001b[1;32m     52\u001b[0m     Int64Dtype,\n\u001b[1;32m     53\u001b[0m     UInt8Dtype,\n\u001b[1;32m     54\u001b[0m     UInt16Dtype,\n\u001b[1;32m     55\u001b[0m     UInt32Dtype,\n\u001b[1;32m     56\u001b[0m     UInt64Dtype,\n\u001b[1;32m     57\u001b[0m     Float32Dtype,\n\u001b[1;32m     58\u001b[0m     Float64Dtype,\n\u001b[1;32m     59\u001b[0m     CategoricalDtype,\n\u001b[1;32m     60\u001b[0m     PeriodDtype,\n\u001b[1;32m     61\u001b[0m     IntervalDtype,\n\u001b[1;32m     62\u001b[0m     DatetimeTZDtype,\n\u001b[1;32m     63\u001b[0m     StringDtype,\n\u001b[1;32m     64\u001b[0m     BooleanDtype,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     NA,\n\u001b[1;32m     67\u001b[0m     isna,\n\u001b[1;32m     68\u001b[0m     isnull,\n\u001b[1;32m     69\u001b[0m     notna,\n\u001b[1;32m     70\u001b[0m     notnull,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     Index,\n\u001b[1;32m     73\u001b[0m     CategoricalIndex,\n\u001b[1;32m     74\u001b[0m     RangeIndex,\n\u001b[1;32m     75\u001b[0m     MultiIndex,\n\u001b[1;32m     76\u001b[0m     IntervalIndex,\n\u001b[1;32m     77\u001b[0m     TimedeltaIndex,\n\u001b[1;32m     78\u001b[0m     DatetimeIndex,\n\u001b[1;32m     79\u001b[0m     PeriodIndex,\n\u001b[1;32m     80\u001b[0m     IndexSlice,\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     NaT,\n\u001b[1;32m     83\u001b[0m     Period,\n\u001b[1;32m     84\u001b[0m     period_range,\n\u001b[1;32m     85\u001b[0m     Timedelta,\n\u001b[1;32m     86\u001b[0m     timedelta_range,\n\u001b[1;32m     87\u001b[0m     Timestamp,\n\u001b[1;32m     88\u001b[0m     date_range,\n\u001b[1;32m     89\u001b[0m     bdate_range,\n\u001b[1;32m     90\u001b[0m     Interval,\n\u001b[1;32m     91\u001b[0m     interval_range,\n\u001b[1;32m     92\u001b[0m     DateOffset,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     to_numeric,\n\u001b[1;32m     95\u001b[0m     to_datetime,\n\u001b[1;32m     96\u001b[0m     to_timedelta,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     Flags,\n\u001b[1;32m     99\u001b[0m     Grouper,\n\u001b[1;32m    100\u001b[0m     factorize,\n\u001b[1;32m    101\u001b[0m     unique,\n\u001b[1;32m    102\u001b[0m     value_counts,\n\u001b[1;32m    103\u001b[0m     NamedAgg,\n\u001b[1;32m    104\u001b[0m     array,\n\u001b[1;32m    105\u001b[0m     Categorical,\n\u001b[1;32m    106\u001b[0m     set_eng_float_format,\n\u001b[1;32m    107\u001b[0m     Series,\n\u001b[1;32m    108\u001b[0m     DataFrame,\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/core/api.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     NaT,\n\u001b[1;32m      3\u001b[0m     Period,\n\u001b[1;32m      4\u001b[0m     Timedelta,\n\u001b[1;32m      5\u001b[0m     Timestamp,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ArrowDtype,\n\u001b[1;32m     11\u001b[0m     CategoricalDtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     PeriodDtype,\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/mgx-chat/lib/python3.10/site-packages/pandas/_libs/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     NaT,\n\u001b[1;32m     21\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     iNaT,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "terminal = Terminal()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "class PermissionMonitoringSystem:\n",
    "    \"\"\"Python implementation of a permission monitoring system for AIvue v2\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the monitoring system with metrics storage\"\"\"\n",
    "        # Cache metrics\n",
    "        self.cache_metrics = {\n",
    "            'hits': 0,\n",
    "            'misses': 0,\n",
    "            'size': 0,\n",
    "            'expirations': 0,\n",
    "            'invalidations': 0,\n",
    "            'hit_rate_history': [],\n",
    "            'timestamps': []\n",
    "        }\n",
    "        \n",
    "        # Permission check metrics\n",
    "        self.permission_metrics = {\n",
    "            'total_checks': 0,\n",
    "            'checks_by_resource': {},\n",
    "            'checks_by_action': {},\n",
    "            'granted': 0,\n",
    "            'denied': 0,\n",
    "            'errors': 0,\n",
    "            'latency': [],\n",
    "            'avg_latency_history': []\n",
    "        }\n",
    "        \n",
    "        # Role management metrics\n",
    "        self.role_metrics = {\n",
    "            'assignments': 0,\n",
    "            'removals': 0,\n",
    "            'users_per_role': {},\n",
    "            'permission_changes': 0\n",
    "        }\n",
    "        \n",
    "        # Security events\n",
    "        self.security_metrics = {\n",
    "            'unauthorized_attempts': 0,\n",
    "            'permission_denials_by_resource': {},\n",
    "            'audit_logs_count': 0\n",
    "        }\n",
    "        \n",
    "        # Edge function metrics\n",
    "        self.edge_metrics = {\n",
    "            'calls': 0,\n",
    "            'errors': 0,\n",
    "            'latency': [],\n",
    "            'avg_latency_history': []\n",
    "        }\n",
    "        \n",
    "        # Event log\n",
    "        self.event_log = []\n",
    "    \n",
    "    def simulate_permission_activity(self, duration_seconds=60, interval=1):\n",
    "        \"\"\"Simulate permission system activity for testing\"\"\"\n",
    "        print(f\"Simulating permission system activity for {duration_seconds} seconds...\")\n",
    "        \n",
    "        resources = ['outlets', 'reviews', 'campaigns', 'users', 'roles', 'permissions']\n",
    "        actions = ['read', 'create', 'update', 'delete']\n",
    "        users = ['user1', 'user2', 'user3', 'admin1', 'admin2']\n",
    "        roles = ['merchant', 'staff', 'admin', 'super_admin']\n",
    "        \n",
    "        start_time = time.time()\n",
    "        end_time = start_time + duration_seconds\n",
    "        \n",
    "        while time.time() < end_time:\n",
    "            # Simulate cache activity\n",
    "            for _ in range(np.random.randint(1, 5)):\n",
    "                if np.random.random() < 0.7:  # 70% hit rate\n",
    "                    self.record_cache_hit()\n",
    "                else:\n",
    "                    self.record_cache_miss()\n",
    "            \n",
    "            # Simulate permission checks\n",
    "            for _ in range(np.random.randint(1, 10)):\n",
    "                resource = np.random.choice(resources)\n",
    "                action = np.random.choice(actions)\n",
    "                user = np.random.choice(users)\n",
    "                latency = np.random.uniform(5, 100)  # ms\n",
    "                \n",
    "                granted = np.random.random() < 0.85  # 85% success rate\n",
    "                self.record_permission_check(user, resource, action, granted, latency)\n",
    "            \n",
    "            # Simulate role changes (less frequent)\n",
    "            if np.random.random() < 0.1:  # 10% chance\n",
    "                user = np.random.choice(users)\n",
    "                role = np.random.choice(roles)\n",
    "                if np.random.random() < 0.7:\n",
    "                    self.record_role_assignment(user, role)\n",
    "                else:\n",
    "                    self.record_role_removal(user, role)\n",
    "            \n",
    "            # Simulate edge function calls\n",
    "            if np.random.random() < 0.3:  # 30% chance\n",
    "                function_name = np.random.choice([\n",
    "                    'app_0be8fb8541_check_permission',\n",
    "                    'app_0be8fb8541_manage_user_role'\n",
    "                ])\n",
    "                success = np.random.random() < 0.95  # 95% success rate\n",
    "                latency = np.random.uniform(50, 500)  # ms\n",
    "                self.record_edge_function_call(function_name, success, latency)\n",
    "            \n",
    "            # Update history at regular intervals\n",
    "            self.update_history()\n",
    "            \n",
    "            # Sleep for the interval\n",
    "            time.sleep(interval)\n",
    "        \n",
    "        print(\"Simulation completed!\")\n",
    "    \n",
    "    def record_cache_hit(self):\n",
    "        \"\"\"Record a cache hit\"\"\"\n",
    "        self.cache_metrics['hits'] += 1\n",
    "        self.log_event('CACHE_HIT', {'timestamp': datetime.now().isoformat()})\n",
    "    \n",
    "    def record_cache_miss(self):\n",
    "        \"\"\"Record a cache miss\"\"\"\n",
    "        self.cache_metrics['misses'] += 1\n",
    "        self.log_event('CACHE_MISS', {'timestamp': datetime.now().isoformat()})\n",
    "    \n",
    "    def record_cache_invalidation(self, user_id):\n",
    "        \"\"\"Record a cache invalidation for a user\"\"\"\n",
    "        self.cache_metrics['invalidations'] += 1\n",
    "        self.log_event('CACHE_INVALIDATION', {\n",
    "            'user_id': user_id,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def record_permission_check(self, user_id, resource, action, granted, latency):\n",
    "        \"\"\"Record a permission check\"\"\"\n",
    "        self.permission_metrics['total_checks'] += 1\n",
    "        \n",
    "        # Track by resource\n",
    "        if resource not in self.permission_metrics['checks_by_resource']:\n",
    "            self.permission_metrics['checks_by_resource'][resource] = 0\n",
    "        self.permission_metrics['checks_by_resource'][resource] += 1\n",
    "        \n",
    "        # Track by action\n",
    "        if action not in self.permission_metrics['checks_by_action']:\n",
    "            self.permission_metrics['checks_by_action'][action] = 0\n",
    "        self.permission_metrics['checks_by_action'][action] += 1\n",
    "        \n",
    "        # Track result\n",
    "        if granted:\n",
    "            self.permission_metrics['granted'] += 1\n",
    "        else:\n",
    "            self.permission_metrics['denied'] += 1\n",
    "            # Track denied permissions by resource\n",
    "            if resource not in self.security_metrics['permission_denials_by_resource']:\n",
    "                self.security_metrics['permission_denials_by_resource'][resource] = 0\n",
    "            self.security_metrics['permission_denials_by_resource'][resource] += 1\n",
    "            \n",
    "            # Track as security event\n",
    "            if resource in ['users', 'roles', 'permissions']:\n",
    "                self.security_metrics['unauthorized_attempts'] += 1\n",
    "        \n",
    "        # Track latency\n",
    "        self.permission_metrics['latency'].append(latency)\n",
    "        \n",
    "        # Log the event\n",
    "        event_type = 'PERMISSION_GRANTED' if granted else 'PERMISSION_DENIED'\n",
    "        self.log_event(event_type, {\n",
    "            'user_id': user_id,\n",
    "            'resource': resource,\n",
    "            'action': action,\n",
    "            'latency': latency,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def record_role_assignment(self, user_id, role_name):\n",
    "        \"\"\"Record a role assignment\"\"\"\n",
    "        self.role_metrics['assignments'] += 1\n",
    "        \n",
    "        # Track users per role\n",
    "        if role_name not in self.role_metrics['users_per_role']:\n",
    "            self.role_metrics['users_per_role'][role_name] = set()\n",
    "        self.role_metrics['users_per_role'][role_name].add(user_id)\n",
    "        \n",
    "        # Log the event\n",
    "        self.log_event('ROLE_ASSIGNED', {\n",
    "            'user_id': user_id,\n",
    "            'role_name': role_name,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Log to audit database (simulated)\n",
    "        self.security_metrics['audit_logs_count'] += 1\n",
    "    \n",
    "    def record_role_removal(self, user_id, role_name):\n",
    "        \"\"\"Record a role removal\"\"\"\n",
    "        self.role_metrics['removals'] += 1\n",
    "        \n",
    "        # Update users per role\n",
    "        if role_name in self.role_metrics['users_per_role'] and user_id in self.role_metrics['users_per_role'][role_name]:\n",
    "            self.role_metrics['users_per_role'][role_name].remove(user_id)\n",
    "        \n",
    "        # Log the event\n",
    "        self.log_event('ROLE_REMOVED', {\n",
    "            'user_id': user_id,\n",
    "            'role_name': role_name,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Log to audit database (simulated)\n",
    "        self.security_metrics['audit_logs_count'] += 1\n",
    "    \n",
    "    def record_edge_function_call(self, function_name, success, latency):\n",
    "        \"\"\"Record an edge function call\"\"\"\n",
    "        self.edge_metrics['calls'] += 1\n",
    "        \n",
    "        if not success:\n",
    "            self.edge_metrics['errors'] += 1\n",
    "        \n",
    "        # Track latency\n",
    "        self.edge_metrics['latency'].append(latency)\n",
    "        \n",
    "        # Log the event\n",
    "        event_type = 'EDGE_FUNCTION_CALL' if success else 'EDGE_FUNCTION_ERROR'\n",
    "        self.log_event(event_type, {\n",
    "            'function': function_name,\n",
    "            'success': success,\n",
    "            'latency': latency,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def log_event(self, event_type, details):\n",
    "        \"\"\"Log an event to the event log\"\"\"\n",
    "        self.event_log.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'event_type': event_type,\n",
    "            'details': details\n",
    "        })\n",
    "        \n",
    "        # Keep event log at a reasonable size\n",
    "        if len(self.event_log) > 1000:\n",
    "            self.event_log = self.event_log[-1000:]\n",
    "    \n",
    "    def update_history(self):\n",
    "        \"\"\"Update historical metrics for trending\"\"\"\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # Update cache hit rate history\n",
    "        total_cache_attempts = self.cache_metrics['hits'] + self.cache_metrics['misses']\n",
    "        hit_rate = self.cache_metrics['hits'] / total_cache_attempts if total_cache_attempts > 0 else 0\n",
    "        self.cache_metrics['hit_rate_history'].append(hit_rate)\n",
    "        self.cache_metrics['timestamps'].append(now)\n",
    "        \n",
    "        # Update average latency history\n",
    "        if self.permission_metrics['latency']:\n",
    "            avg_latency = sum(self.permission_metrics['latency']) / len(self.permission_metrics['latency'])\n",
    "            self.permission_metrics['avg_latency_history'].append(avg_latency)\n",
    "        \n",
    "        # Update edge function latency history\n",
    "        if self.edge_metrics['latency']:\n",
    "            avg_edge_latency = sum(self.edge_metrics['latency']) / len(self.edge_metrics['latency'])\n",
    "            self.edge_metrics['avg_latency_history'].append(avg_edge_latency)\n",
    "        \n",
    "        # Keep histories at a reasonable size\n",
    "        max_history = 1000\n",
    "        if len(self.cache_metrics['hit_rate_history']) > max_history:\n",
    "            self.cache_metrics['hit_rate_history'] = self.cache_metrics['hit_rate_history'][-max_history:]\n",
    "            self.cache_metrics['timestamps'] = self.cache_metrics['timestamps'][-max_history:]\n",
    "        \n",
    "        if len(self.permission_metrics['avg_latency_history']) > max_history:\n",
    "            self.permission_metrics['avg_latency_history'] = self.permission_metrics['avg_latency_history'][-max_history:]\n",
    "        \n",
    "        if len(self.edge_metrics['avg_latency_history']) > max_history:\n",
    "            self.edge_metrics['avg_latency_history'] = self.edge_metrics['avg_latency_history'][-max_history:]\n",
    "    \n",
    "    def get_metrics_summary(self):\n",
    "        \"\"\"Get a summary of all metrics\"\"\"\n",
    "        # Calculate derived metrics\n",
    "        total_cache_attempts = self.cache_metrics['hits'] + self.cache_metrics['misses']\n",
    "        cache_hit_rate = self.cache_metrics['hits'] / total_cache_attempts if total_cache_attempts > 0 else 0\n",
    "        \n",
    "        avg_permission_latency = np.mean(self.permission_metrics['latency']) if self.permission_metrics['latency'] else 0\n",
    "        avg_edge_latency = np.mean(self.edge_metrics['latency']) if self.edge_metrics['latency'] else 0\n",
    "        \n",
    "        return {\n",
    "            'cache': {\n",
    "                'hit_rate': cache_hit_rate,\n",
    "                'hits': self.cache_metrics['hits'],\n",
    "                'misses': self.cache_metrics['misses'],\n",
    "                'invalidations': self.cache_metrics['invalidations']\n",
    "            },\n",
    "            'permissions': {\n",
    "                'total_checks': self.permission_metrics['total_checks'],\n",
    "                'granted_rate': self.permission_metrics['granted'] / self.permission_metrics['total_checks'] \n",
    "                               if self.permission_metrics['total_checks'] > 0 else 0,\n",
    "                'avg_latency_ms': avg_permission_latency,\n",
    "                'top_resources': dict(sorted(self.permission_metrics['checks_by_resource'].items(), \n",
    "                                             key=lambda x: x[1], reverse=True)[:5])\n",
    "            },\n",
    "            'roles': {\n",
    "                'assignments': self.role_metrics['assignments'],\n",
    "                'removals': self.role_metrics['removals'],\n",
    "                'users_by_role': {role: len(users) for role, users in self.role_metrics['users_per_role'].items()}\n",
    "            },\n",
    "            'security': {\n",
    "                'unauthorized_attempts': self.security_metrics['unauthorized_attempts'],\n",
    "                'permission_denials': sum(self.security_metrics['permission_denials_by_resource'].values()),\n",
    "                'audit_logs': self.security_metrics['audit_logs_count']\n",
    "            },\n",
    "            'edge_functions': {\n",
    "                'calls': self.edge_metrics['calls'],\n",
    "                'error_rate': self.edge_metrics['errors'] / self.edge_metrics['calls'] \n",
    "                              if self.edge_metrics['calls'] > 0 else 0,\n",
    "                'avg_latency_ms': avg_edge_latency\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def visualize_metrics(self):\n",
    "        \"\"\"Visualize key metrics with matplotlib\"\"\"\n",
    "        metrics = self.get_metrics_summary()\n",
    "        \n",
    "        # Set up the figure with subplots\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # 1. Cache Performance\n",
    "        ax1 = fig.add_subplot(2, 3, 1)\n",
    "        cache_labels = ['Hits', 'Misses']\n",
    "        cache_values = [self.cache_metrics['hits'], self.cache_metrics['misses']]\n",
    "        ax1.pie(cache_values, labels=cache_labels, autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#F44336'])\n",
    "        ax1.set_title('Cache Performance')\n",
    "        \n",
    "        # 2. Permission Checks by Resource\n",
    "        ax2 = fig.add_subplot(2, 3, 2)\n",
    "        resources = list(metrics['permissions']['top_resources'].keys())\n",
    "        checks = list(metrics['permissions']['top_resources'].values())\n",
    "        ax2.bar(resources, checks, color='#2196F3')\n",
    "        ax2.set_title('Top Resources Accessed')\n",
    "        ax2.set_ylabel('Number of Checks')\n",
    "        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # 3. Permission Results\n",
    "        ax3 = fig.add_subplot(2, 3, 3)\n",
    "        results_labels = ['Granted', 'Denied']\n",
    "        results_values = [self.permission_metrics['granted'], self.permission_metrics['denied']]\n",
    "        ax3.pie(results_values, labels=results_labels, autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#F44336'])\n",
    "        ax3.set_title('Permission Check Results')\n",
    "        \n",
    "        # 4. Cache Hit Rate Over Time\n",
    "        ax4 = fig.add_subplot(2, 3, 4)\n",
    "        if len(self.cache_metrics['hit_rate_history']) > 1:\n",
    "            ax4.plot(self.cache_metrics['timestamps'][-30:], self.cache_metrics['hit_rate_history'][-30:], 'g-')\n",
    "            ax4.set_title('Cache Hit Rate (Recent)')\n",
    "            ax4.set_ylabel('Hit Rate')\n",
    "            ax4.set_ylim(0, 1)\n",
    "            plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, 'Insufficient data', horizontalalignment='center', verticalalignment='center')\n",
    "            ax4.set_title('Cache Hit Rate (Recent)')\n",
    "        \n",
    "        # 5. Users Per Role\n",
    "        ax5 = fig.add_subplot(2, 3, 5)\n",
    "        roles = list(metrics['roles']['users_by_role'].keys())\n",
    "        user_counts = list(metrics['roles']['users_by_role'].values())\n",
    "        if roles:\n",
    "            ax5.bar(roles, user_counts, color='#9C27B0')\n",
    "            ax5.set_title('Users Per Role')\n",
    "            ax5.set_ylabel('Number of Users')\n",
    "            plt.setp(ax5.get_xticklabels(), rotation=45, ha='right')\n",
    "        else:\n",
    "            ax5.text(0.5, 0.5, 'No role data available', horizontalalignment='center', verticalalignment='center')\n",
    "            ax5.set_title('Users Per Role')\n",
    "        \n",
    "        # 6. Security Metrics\n",
    "        ax6 = fig.add_subplot(2, 3, 6)\n",
    "        security_labels = ['Unauthorized\\nAttempts', 'Permission\\nDenials', 'Audit\\nLogs']\n",
    "        security_values = [\n",
    "            metrics['security']['unauthorized_attempts'],\n",
    "            metrics['security']['permission_denials'],\n",
    "            metrics['security']['audit_logs']\n",
    "        ]\n",
    "        ax6.bar(security_labels, security_values, color='#FF9800')\n",
    "        ax6.set_title('Security Metrics')\n",
    "        ax6.set_ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('permission_monitoring_dashboard.png')\n",
    "        plt.close()\n",
    "        \n",
    "        return \"Permission monitoring visualizations created and saved as 'permission_monitoring_dashboard.png'\"\n",
    "\n",
    "# Create a monitoring system and simulate some activity\n",
    "monitoring_system = PermissionMonitoringSystem()\n",
    "monitoring_system.simulate_permission_activity(duration_seconds=5)\n",
    "\n",
    "# Generate visualization\n",
    "visualization_result = monitoring_system.visualize_metrics()\n",
    "print(visualization_result)\n",
    "\n",
    "# Display metrics summary\n",
    "metrics_summary = monitoring_system.get_metrics_summary()\n",
    "print(\"\\nPermission System Metrics Summary:\")\n",
    "print(json.dumps(metrics_summary, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c392abd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-27T16:29:35.725480Z",
     "iopub.status.busy": "2025-07-27T16:29:35.725089Z",
     "iopub.status.idle": "2025-07-27T16:29:40.915485Z",
     "shell.execute_reply": "2025-07-27T16:29:40.914945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating permission system activity for 5 seconds...\n",
      "Simulation completed!\n",
      "Visualization created successfully.\n",
      "\n",
      "Permission monitoring visualization saved as 'permission_monitoring_dashboard_simple.png'\n",
      "\n",
      "Permission System Metrics Summary (JSON format):\n",
      "{\n",
      "  \"cache\": {\n",
      "    \"hit_rate\": 0.5714285714285714,\n",
      "    \"hits\": 8,\n",
      "    \"misses\": 6,\n",
      "    \"invalidations\": 0\n",
      "  },\n",
      "  \"permissions\": {\n",
      "    \"total_checks\": 26,\n",
      "    \"granted_rate\": 0.9615384615384616,\n",
      "    \"avg_latency_ms\": 46.12750349504604,\n",
      "    \"top_resources\": {\n",
      "      \"outlets\": 6,\n",
      "      \"permissions\": 5,\n",
      "      \"reviews\": 5,\n",
      "      \"campaigns\": 4,\n",
      "      \"roles\": 3\n",
      "    }\n",
      "  },\n",
      "  \"roles\": {\n",
      "    \"assignments\": 0,\n",
      "    \"removals\": 0,\n",
      "    \"users_by_role\": {}\n",
      "  },\n",
      "  \"security\": {\n",
      "    \"unauthorized_attempts\": 1,\n",
      "    \"permission_denials\": 1,\n",
      "    \"audit_logs\": 0\n",
      "  },\n",
      "  \"edge_functions\": {\n",
      "    \"calls\": 1,\n",
      "    \"error_rate\": 0.0,\n",
      "    \"avg_latency_ms\": 446.6331732063254\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.terminal import Terminal\n",
    "terminal = Terminal()\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class PermissionMonitoringSystem:\n",
    "    \"\"\"Python implementation of a permission monitoring system for AIvue v2\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the monitoring system with metrics storage\"\"\"\n",
    "        # Cache metrics\n",
    "        self.cache_metrics = {\n",
    "            'hits': 0,\n",
    "            'misses': 0,\n",
    "            'size': 0,\n",
    "            'expirations': 0,\n",
    "            'invalidations': 0,\n",
    "            'hit_rate_history': [],\n",
    "            'timestamps': []\n",
    "        }\n",
    "        \n",
    "        # Permission check metrics\n",
    "        self.permission_metrics = {\n",
    "            'total_checks': 0,\n",
    "            'checks_by_resource': {},\n",
    "            'checks_by_action': {},\n",
    "            'granted': 0,\n",
    "            'denied': 0,\n",
    "            'errors': 0,\n",
    "            'latency': [],\n",
    "            'avg_latency_history': []\n",
    "        }\n",
    "        \n",
    "        # Role management metrics\n",
    "        self.role_metrics = {\n",
    "            'assignments': 0,\n",
    "            'removals': 0,\n",
    "            'users_per_role': {},\n",
    "            'permission_changes': 0\n",
    "        }\n",
    "        \n",
    "        # Security events\n",
    "        self.security_metrics = {\n",
    "            'unauthorized_attempts': 0,\n",
    "            'permission_denials_by_resource': {},\n",
    "            'audit_logs_count': 0\n",
    "        }\n",
    "        \n",
    "        # Edge function metrics\n",
    "        self.edge_metrics = {\n",
    "            'calls': 0,\n",
    "            'errors': 0,\n",
    "            'latency': [],\n",
    "            'avg_latency_history': []\n",
    "        }\n",
    "        \n",
    "        # Event log\n",
    "        self.event_log = []\n",
    "    \n",
    "    def simulate_permission_activity(self, duration_seconds=60, interval=1):\n",
    "        \"\"\"Simulate permission system activity for testing\"\"\"\n",
    "        print(f\"Simulating permission system activity for {duration_seconds} seconds...\")\n",
    "        \n",
    "        resources = ['outlets', 'reviews', 'campaigns', 'users', 'roles', 'permissions']\n",
    "        actions = ['read', 'create', 'update', 'delete']\n",
    "        users = ['user1', 'user2', 'user3', 'admin1', 'admin2']\n",
    "        roles = ['merchant', 'staff', 'admin', 'super_admin']\n",
    "        \n",
    "        import random  # Using standard library random instead of numpy\n",
    "        \n",
    "        start_time = time.time()\n",
    "        end_time = start_time + duration_seconds\n",
    "        \n",
    "        while time.time() < end_time:\n",
    "            # Simulate cache activity\n",
    "            for _ in range(random.randint(1, 5)):\n",
    "                if random.random() < 0.7:  # 70% hit rate\n",
    "                    self.record_cache_hit()\n",
    "                else:\n",
    "                    self.record_cache_miss()\n",
    "            \n",
    "            # Simulate permission checks\n",
    "            for _ in range(random.randint(1, 10)):\n",
    "                resource = random.choice(resources)\n",
    "                action = random.choice(actions)\n",
    "                user = random.choice(users)\n",
    "                latency = random.uniform(5, 100)  # ms\n",
    "                \n",
    "                granted = random.random() < 0.85  # 85% success rate\n",
    "                self.record_permission_check(user, resource, action, granted, latency)\n",
    "            \n",
    "            # Simulate role changes (less frequent)\n",
    "            if random.random() < 0.1:  # 10% chance\n",
    "                user = random.choice(users)\n",
    "                role = random.choice(roles)\n",
    "                if random.random() < 0.7:\n",
    "                    self.record_role_assignment(user, role)\n",
    "                else:\n",
    "                    self.record_role_removal(user, role)\n",
    "            \n",
    "            # Simulate edge function calls\n",
    "            if random.random() < 0.3:  # 30% chance\n",
    "                function_name = random.choice([\n",
    "                    'app_0be8fb8541_check_permission',\n",
    "                    'app_0be8fb8541_manage_user_role'\n",
    "                ])\n",
    "                success = random.random() < 0.95  # 95% success rate\n",
    "                latency = random.uniform(50, 500)  # ms\n",
    "                self.record_edge_function_call(function_name, success, latency)\n",
    "            \n",
    "            # Update history at regular intervals\n",
    "            self.update_history()\n",
    "            \n",
    "            # Sleep for the interval\n",
    "            time.sleep(interval)\n",
    "        \n",
    "        print(\"Simulation completed!\")\n",
    "    \n",
    "    def record_cache_hit(self):\n",
    "        \"\"\"Record a cache hit\"\"\"\n",
    "        self.cache_metrics['hits'] += 1\n",
    "        self.log_event('CACHE_HIT', {'timestamp': datetime.now().isoformat()})\n",
    "    \n",
    "    def record_cache_miss(self):\n",
    "        \"\"\"Record a cache miss\"\"\"\n",
    "        self.cache_metrics['misses'] += 1\n",
    "        self.log_event('CACHE_MISS', {'timestamp': datetime.now().isoformat()})\n",
    "    \n",
    "    def record_cache_invalidation(self, user_id):\n",
    "        \"\"\"Record a cache invalidation for a user\"\"\"\n",
    "        self.cache_metrics['invalidations'] += 1\n",
    "        self.log_event('CACHE_INVALIDATION', {\n",
    "            'user_id': user_id,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def record_permission_check(self, user_id, resource, action, granted, latency):\n",
    "        \"\"\"Record a permission check\"\"\"\n",
    "        self.permission_metrics['total_checks'] += 1\n",
    "        \n",
    "        # Track by resource\n",
    "        if resource not in self.permission_metrics['checks_by_resource']:\n",
    "            self.permission_metrics['checks_by_resource'][resource] = 0\n",
    "        self.permission_metrics['checks_by_resource'][resource] += 1\n",
    "        \n",
    "        # Track by action\n",
    "        if action not in self.permission_metrics['checks_by_action']:\n",
    "            self.permission_metrics['checks_by_action'][action] = 0\n",
    "        self.permission_metrics['checks_by_action'][action] += 1\n",
    "        \n",
    "        # Track result\n",
    "        if granted:\n",
    "            self.permission_metrics['granted'] += 1\n",
    "        else:\n",
    "            self.permission_metrics['denied'] += 1\n",
    "            # Track denied permissions by resource\n",
    "            if resource not in self.security_metrics['permission_denials_by_resource']:\n",
    "                self.security_metrics['permission_denials_by_resource'][resource] = 0\n",
    "            self.security_metrics['permission_denials_by_resource'][resource] += 1\n",
    "            \n",
    "            # Track as security event\n",
    "            if resource in ['users', 'roles', 'permissions']:\n",
    "                self.security_metrics['unauthorized_attempts'] += 1\n",
    "        \n",
    "        # Track latency\n",
    "        self.permission_metrics['latency'].append(latency)\n",
    "        \n",
    "        # Log the event\n",
    "        event_type = 'PERMISSION_GRANTED' if granted else 'PERMISSION_DENIED'\n",
    "        self.log_event(event_type, {\n",
    "            'user_id': user_id,\n",
    "            'resource': resource,\n",
    "            'action': action,\n",
    "            'latency': latency,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def record_role_assignment(self, user_id, role_name):\n",
    "        \"\"\"Record a role assignment\"\"\"\n",
    "        self.role_metrics['assignments'] += 1\n",
    "        \n",
    "        # Track users per role\n",
    "        if role_name not in self.role_metrics['users_per_role']:\n",
    "            self.role_metrics['users_per_role'][role_name] = set()\n",
    "        self.role_metrics['users_per_role'][role_name].add(user_id)\n",
    "        \n",
    "        # Log the event\n",
    "        self.log_event('ROLE_ASSIGNED', {\n",
    "            'user_id': user_id,\n",
    "            'role_name': role_name,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Log to audit database (simulated)\n",
    "        self.security_metrics['audit_logs_count'] += 1\n",
    "    \n",
    "    def record_role_removal(self, user_id, role_name):\n",
    "        \"\"\"Record a role removal\"\"\"\n",
    "        self.role_metrics['removals'] += 1\n",
    "        \n",
    "        # Update users per role\n",
    "        if role_name in self.role_metrics['users_per_role'] and user_id in self.role_metrics['users_per_role'][role_name]:\n",
    "            self.role_metrics['users_per_role'][role_name].remove(user_id)\n",
    "        \n",
    "        # Log the event\n",
    "        self.log_event('ROLE_REMOVED', {\n",
    "            'user_id': user_id,\n",
    "            'role_name': role_name,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # Log to audit database (simulated)\n",
    "        self.security_metrics['audit_logs_count'] += 1\n",
    "    \n",
    "    def record_edge_function_call(self, function_name, success, latency):\n",
    "        \"\"\"Record an edge function call\"\"\"\n",
    "        self.edge_metrics['calls'] += 1\n",
    "        \n",
    "        if not success:\n",
    "            self.edge_metrics['errors'] += 1\n",
    "        \n",
    "        # Track latency\n",
    "        self.edge_metrics['latency'].append(latency)\n",
    "        \n",
    "        # Log the event\n",
    "        event_type = 'EDGE_FUNCTION_CALL' if success else 'EDGE_FUNCTION_ERROR'\n",
    "        self.log_event(event_type, {\n",
    "            'function': function_name,\n",
    "            'success': success,\n",
    "            'latency': latency,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    def log_event(self, event_type, details):\n",
    "        \"\"\"Log an event to the event log\"\"\"\n",
    "        self.event_log.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'event_type': event_type,\n",
    "            'details': details\n",
    "        })\n",
    "        \n",
    "        # Keep event log at a reasonable size\n",
    "        if len(self.event_log) > 1000:\n",
    "            self.event_log = self.event_log[-1000:]\n",
    "    \n",
    "    def update_history(self):\n",
    "        \"\"\"Update historical metrics for trending\"\"\"\n",
    "        now = datetime.now()\n",
    "        \n",
    "        # Update cache hit rate history\n",
    "        total_cache_attempts = self.cache_metrics['hits'] + self.cache_metrics['misses']\n",
    "        hit_rate = self.cache_metrics['hits'] / total_cache_attempts if total_cache_attempts > 0 else 0\n",
    "        self.cache_metrics['hit_rate_history'].append(hit_rate)\n",
    "        self.cache_metrics['timestamps'].append(now)\n",
    "        \n",
    "        # Update average latency history\n",
    "        if self.permission_metrics['latency']:\n",
    "            avg_latency = sum(self.permission_metrics['latency']) / len(self.permission_metrics['latency'])\n",
    "            self.permission_metrics['avg_latency_history'].append(avg_latency)\n",
    "        \n",
    "        # Update edge function latency history\n",
    "        if self.edge_metrics['latency']:\n",
    "            avg_edge_latency = sum(self.edge_metrics['latency']) / len(self.edge_metrics['latency'])\n",
    "            self.edge_metrics['avg_latency_history'].append(avg_edge_latency)\n",
    "        \n",
    "        # Keep histories at a reasonable size\n",
    "        max_history = 1000\n",
    "        if len(self.cache_metrics['hit_rate_history']) > max_history:\n",
    "            self.cache_metrics['hit_rate_history'] = self.cache_metrics['hit_rate_history'][-max_history:]\n",
    "            self.cache_metrics['timestamps'] = self.cache_metrics['timestamps'][-max_history:]\n",
    "        \n",
    "        if len(self.permission_metrics['avg_latency_history']) > max_history:\n",
    "            self.permission_metrics['avg_latency_history'] = self.permission_metrics['avg_latency_history'][-max_history:]\n",
    "        \n",
    "        if len(self.edge_metrics['avg_latency_history']) > max_history:\n",
    "            self.edge_metrics['avg_latency_history'] = self.edge_metrics['avg_latency_history'][-max_history:]\n",
    "    \n",
    "    def get_metrics_summary(self):\n",
    "        \"\"\"Get a summary of all metrics\"\"\"\n",
    "        # Calculate derived metrics\n",
    "        total_cache_attempts = self.cache_metrics['hits'] + self.cache_metrics['misses']\n",
    "        cache_hit_rate = self.cache_metrics['hits'] / total_cache_attempts if total_cache_attempts > 0 else 0\n",
    "        \n",
    "        avg_permission_latency = 0\n",
    "        if self.permission_metrics['latency']:\n",
    "            avg_permission_latency = sum(self.permission_metrics['latency']) / len(self.permission_metrics['latency'])\n",
    "        \n",
    "        avg_edge_latency = 0\n",
    "        if self.edge_metrics['latency']:\n",
    "            avg_edge_latency = sum(self.edge_metrics['latency']) / len(self.edge_metrics['latency'])\n",
    "        \n",
    "        # Sort resources by check count\n",
    "        sorted_resources = sorted(\n",
    "            self.permission_metrics['checks_by_resource'].items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        top_resources = dict(sorted_resources[:5])\n",
    "        \n",
    "        return {\n",
    "            'cache': {\n",
    "                'hit_rate': cache_hit_rate,\n",
    "                'hits': self.cache_metrics['hits'],\n",
    "                'misses': self.cache_metrics['misses'],\n",
    "                'invalidations': self.cache_metrics['invalidations']\n",
    "            },\n",
    "            'permissions': {\n",
    "                'total_checks': self.permission_metrics['total_checks'],\n",
    "                'granted_rate': self.permission_metrics['granted'] / self.permission_metrics['total_checks'] \n",
    "                               if self.permission_metrics['total_checks'] > 0 else 0,\n",
    "                'avg_latency_ms': avg_permission_latency,\n",
    "                'top_resources': top_resources\n",
    "            },\n",
    "            'roles': {\n",
    "                'assignments': self.role_metrics['assignments'],\n",
    "                'removals': self.role_metrics['removals'],\n",
    "                'users_by_role': {role: len(users) for role, users in self.role_metrics['users_per_role'].items()}\n",
    "            },\n",
    "            'security': {\n",
    "                'unauthorized_attempts': self.security_metrics['unauthorized_attempts'],\n",
    "                'permission_denials': sum(self.security_metrics['permission_denials_by_resource'].values()),\n",
    "                'audit_logs': self.security_metrics['audit_logs_count']\n",
    "            },\n",
    "            'edge_functions': {\n",
    "                'calls': self.edge_metrics['calls'],\n",
    "                'error_rate': self.edge_metrics['errors'] / self.edge_metrics['calls'] \n",
    "                              if self.edge_metrics['calls'] > 0 else 0,\n",
    "                'avg_latency_ms': avg_edge_latency\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_text_report(self):\n",
    "        \"\"\"Generate a text-based report of the monitoring metrics\"\"\"\n",
    "        metrics = self.get_metrics_summary()\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(\"PERMISSION SYSTEM MONITORING REPORT\")\n",
    "        report.append(f\"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        # Cache metrics\n",
    "        report.append(\"\\nCACHE PERFORMANCE\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Hit Rate: {metrics['cache']['hit_rate']:.2%}\")\n",
    "        report.append(f\"Hits: {metrics['cache']['hits']}\")\n",
    "        report.append(f\"Misses: {metrics['cache']['misses']}\")\n",
    "        report.append(f\"Invalidations: {metrics['cache']['invalidations']}\")\n",
    "        \n",
    "        # Permission metrics\n",
    "        report.append(\"\\nPERMISSION CHECKS\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Total Checks: {metrics['permissions']['total_checks']}\")\n",
    "        report.append(f\"Grant Rate: {metrics['permissions']['granted_rate']:.2%}\")\n",
    "        report.append(f\"Avg Latency: {metrics['permissions']['avg_latency_ms']:.2f} ms\")\n",
    "        \n",
    "        report.append(\"\\nTop Resources:\")\n",
    "        for resource, count in metrics['permissions']['top_resources'].items():\n",
    "            report.append(f\"  - {resource}: {count} checks\")\n",
    "        \n",
    "        # Role metrics\n",
    "        report.append(\"\\nROLE MANAGEMENT\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Role Assignments: {metrics['roles']['assignments']}\")\n",
    "        report.append(f\"Role Removals: {metrics['roles']['removals']}\")\n",
    "        \n",
    "        report.append(\"\\nUsers per Role:\")\n",
    "        for role, count in metrics['roles']['users_by_role'].items():\n",
    "            report.append(f\"  - {role}: {count} users\")\n",
    "        \n",
    "        # Security metrics\n",
    "        report.append(\"\\nSECURITY METRICS\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Unauthorized Access Attempts: {metrics['security']['unauthorized_attempts']}\")\n",
    "        report.append(f\"Permission Denials: {metrics['security']['permission_denials']}\")\n",
    "        report.append(f\"Audit Log Entries: {metrics['security']['audit_logs']}\")\n",
    "        \n",
    "        # Edge function metrics\n",
    "        report.append(\"\\nEDGE FUNCTION PERFORMANCE\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"Total Calls: {metrics['edge_functions']['calls']}\")\n",
    "        report.append(f\"Error Rate: {metrics['edge_functions']['error_rate']:.2%}\")\n",
    "        report.append(f\"Avg Latency: {metrics['edge_functions']['avg_latency_ms']:.2f} ms\")\n",
    "        \n",
    "        # Recent Events\n",
    "        report.append(\"\\nRECENT EVENTS\")\n",
    "        report.append(\"-\" * 30)\n",
    "        \n",
    "        recent_events = self.event_log[-10:] if len(self.event_log) > 10 else self.event_log\n",
    "        for event in recent_events:\n",
    "            timestamp = event['timestamp'].strftime('%H:%M:%S')\n",
    "            event_type = event['event_type']\n",
    "            report.append(f\"{timestamp} - {event_type}\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\" * 60)\n",
    "        \n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "    def create_dashboard(self):\n",
    "        \"\"\"\n",
    "        Create a simple console-based dashboard\n",
    "        This will be used when matplotlib is not available\n",
    "        \"\"\"\n",
    "        return self.generate_text_report()\n",
    "\n",
    "    def try_create_visualization(self):\n",
    "        \"\"\"Try to create visualizations with matplotlib, fall back to text if not available\"\"\"\n",
    "        try:\n",
    "            metrics = self.get_metrics_summary()\n",
    "            \n",
    "            # Set up the figure with subplots\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Just create a simple text figure with the metrics\n",
    "            plt.text(0.1, 0.9, \"Permission System Monitoring Dashboard\", fontsize=16)\n",
    "            plt.text(0.1, 0.8, f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", fontsize=12)\n",
    "            \n",
    "            # Cache metrics\n",
    "            plt.text(0.1, 0.7, f\"Cache Hit Rate: {metrics['cache']['hit_rate']:.2%}\", fontsize=12)\n",
    "            plt.text(0.1, 0.65, f\"Permission Checks: {metrics['permissions']['total_checks']}\", fontsize=12)\n",
    "            plt.text(0.1, 0.6, f\"Permission Grant Rate: {metrics['permissions']['granted_rate']:.2%}\", fontsize=12)\n",
    "            \n",
    "            # Security metrics\n",
    "            plt.text(0.1, 0.5, f\"Unauthorized Access Attempts: {metrics['security']['unauthorized_attempts']}\", fontsize=12)\n",
    "            plt.text(0.1, 0.45, f\"Permission Denials: {metrics['security']['permission_denials']}\", fontsize=12)\n",
    "            \n",
    "            # Role metrics\n",
    "            plt.text(0.5, 0.7, f\"Role Assignments: {metrics['roles']['assignments']}\", fontsize=12)\n",
    "            plt.text(0.5, 0.65, f\"Role Removals: {metrics['roles']['removals']}\", fontsize=12)\n",
    "            \n",
    "            # Edge function metrics\n",
    "            plt.text(0.5, 0.5, f\"Edge Function Calls: {metrics['edge_functions']['calls']}\", fontsize=12)\n",
    "            plt.text(0.5, 0.45, f\"Edge Function Error Rate: {metrics['edge_functions']['error_rate']:.2%}\", fontsize=12)\n",
    "            \n",
    "            # Add notes\n",
    "            plt.text(0.1, 0.3, \"Note: This is a simplified visualization dashboard.\", fontsize=10)\n",
    "            plt.text(0.1, 0.25, \"For detailed metrics, please view the text report.\", fontsize=10)\n",
    "            \n",
    "            plt.axis('off')  # Hide axes\n",
    "            plt.savefig('permission_monitoring_dashboard_simple.png')\n",
    "            plt.close()\n",
    "            \n",
    "            return \"Permission monitoring visualization saved as 'permission_monitoring_dashboard_simple.png'\"\n",
    "        except Exception as e:\n",
    "            print(f\"Visualization failed: {e}. Falling back to text report.\")\n",
    "            return self.generate_text_report()\n",
    "\n",
    "# Create a monitoring system and simulate some activity\n",
    "monitoring_system = PermissionMonitoringSystem()\n",
    "monitoring_system.simulate_permission_activity(duration_seconds=5)\n",
    "\n",
    "# Generate visualization or text report based on what's available\n",
    "try:\n",
    "    visualization_result = monitoring_system.try_create_visualization()\n",
    "    print(\"Visualization created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not create visualization: {e}\")\n",
    "    print(\"Falling back to text report...\")\n",
    "    visualization_result = monitoring_system.create_dashboard()\n",
    "\n",
    "# Display report\n",
    "print(\"\\n\" + visualization_result)\n",
    "\n",
    "# Display metrics summary\n",
    "metrics_summary = monitoring_system.get_metrics_summary()\n",
    "print(\"\\nPermission System Metrics Summary (JSON format):\")\n",
    "print(json.dumps(metrics_summary, indent=2, default=str))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
